{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_survey_data = pd.read_csv('./raw data.csv', low_memory = False)\n",
    "prolific_data = pd.read_csv('./prolific data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step1: filter unfinished, time-out samples and fail to pass example participants by prolific summary\n",
    "\n",
    "Note*: there are two participants didn't fill participant id correctly, after matching prolific data file and raw data file, we delete these two subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 20)\n",
      "(745, 3522)\n"
     ]
    }
   ],
   "source": [
    "approve_prolific = prolific_data[prolific_data.Status == 'APPROVED']\n",
    "print(approve_prolific.shape)\n",
    "approve_prolific.to_csv('check_prolific.csv')\n",
    "survey_data = raw_survey_data\n",
    "survey_data['Q1324'] = survey_data['Q1324'].str.lower()\n",
    "survey_data['Q1324'] = survey_data.Q1324.str.split('@').str[0]\n",
    "df = survey_data[survey_data.set_index(['Q1324']).index.isin(approve_prolific.set_index(['Participant id']).index)]\n",
    "colum_name = survey_data[:1]\n",
    "df1 = pd.concat([colum_name, df], ignore_index = True)\n",
    "print(df1.shape)\n",
    "df1.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step2: tansfer the demogaphic data\n",
    "Note*: 1 for frequently buy online; 1 for not familar with shampoo; 1 for not clear image;1 for fully display; 1 for not slow internet; 1 for youunger than 20 years old; 1 for male(female, non-binary, perfer self-discrible, not to say)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(745, 3522)\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.replace({'demo_buy_online': {'Yes': 1, 'No': 0},'demo_familarity_1': {'Not familiar at all': 1, 'Slightly familiar': 2,'Moderately familiar': 3,'Very familiar': 4,'Extremely familiar': 5},\n",
    "                 'demo_img_clear_1': {'Not clear at all': 1, 'Slightly clear': 2,'Moderately clear': 3,'Very clear': 4,'Extremely clear': 5},'demo_img_complete': {'Yes': 1, 'Partial': 0, 'No': 0},\n",
    "                 'demo_internet_1': {'Not slow at all': 1, 'Slightly slow': 2,'Moderately slow': 3,'Very slow': 4,'Extremely slow': 5},\n",
    "                 'Qage': {'Younger than 20 years': 1, 'Between 20 and 29 years': 2,'Between 30 and 39 years': 3,'Between 40 and 49 years': 4,'Between 50 and 59 years': 5, '60 years or older': 6},\n",
    "                 'Qgender': {'Male': 0, 'Female': 1,'Non-binary': 0,'Prefer to self-describe': 0,'Prefer not to say': 0}\n",
    "                })\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3: remove subjects who state the internet is exteremely slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741, 3522)\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.drop(df2[df2.demo_internet_1 == 5].index)\n",
    "print(df3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step4: 1). divide subjects into two experiment condition: no time pressure(0) or time pressure(1) \n",
    "       2). indicate version, either original(0) or changed(1)\n",
    "       3). indicate correctly find the target or not\n",
    "       4). indicate number of selected region\n",
    "       5). indicate search time, by first click time, last click time, page submission \n",
    "Note*: q_change3_shelf17 set to like/dislike --> on/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['condition'] = df3['Q572_Page Submit'].isnull()*1\n",
    "df3 = df3.replace(['Neutral', 'Dislike'], 'Off') \n",
    "df3 = df3.replace('Like', 'On') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(df, packNum, shelfNum, verNum, bottleNum):\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    version_column = ['Q937_Page Submit', 'Q944_Page Submit','Q959_Page Submit']\n",
    "    original_no_time_colum = ['Q902', 'Q816', 'Q1169']\n",
    "    change_no_time_column = ['Q1048', 'Q992', 'Q1102']\n",
    "    for n in tqdm(range(1, packNum + 1)):\n",
    "        df_copy['version' + str(n)] = df[version_column[n-1]].isnull() * 1 \n",
    "        conditions = []\n",
    "        choices = [1] * shelfNum * verNum\n",
    "        column_name_start = 'q_' + 'original' + str(n) + '_' + 'shelf1_1'\n",
    "        column_loc_start = df.columns.get_loc(column_name_start)\n",
    "        for i in range(1, shelfNum + 1):\n",
    "            for m in range(verNum):\n",
    "                if m==0:\n",
    "                    version = 'original'\n",
    "                else:\n",
    "                    version = 'change'\n",
    "                column_name = 'q_' + version + str(n) + '_' + 'shelf' + str(i) +' - target'\n",
    "                shelf_target = df.where(df.eq(column_name)).stack().index.tolist()[-1][-1]\n",
    "                column_loc = df.columns.get_loc(shelf_target)\n",
    "                conditions.append(df.iloc[:, column_loc].eq('On'))\n",
    "        df_copy['count'+ str(n)] = df.iloc[:, column_loc_start:int(column_loc_start + shelfNum * verNum * bottleNum + 12)].eq('On').sum(axis = 1)\n",
    "        df_copy['correct'+ str(n)] = np.select(conditions, choices, default = 0)\n",
    "        df_copy['time_first click' + str(n)] = df[original_no_time_colum[n - 1] + '_First Click'].combine_first(df[change_no_time_column[n - 1] + '_First Click'])\n",
    "        df_copy['time_last click' + str(n)] = df[original_no_time_colum[n - 1] + '_Last Click'].combine_first(df[change_no_time_column[n - 1] + '_Last Click'])\n",
    "        df_copy['time_click count' + str(n)] = df[original_no_time_colum[n - 1] + '_Click Count'].combine_first(df[change_no_time_column[n - 1] + '_Click Count'])\n",
    "    return(df_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [01:10<00:00, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index        StartDate          EndDate         Status        IPAddress  \\\n",
      "0        0       Start Date         End Date  Response Type       IP Address   \n",
      "1        1  24/12/2024 2:08  24/12/2024 2:11     IP Address  185.241.224.233   \n",
      "2        2  24/12/2024 2:08  24/12/2024 2:12     IP Address     83.98.59.146   \n",
      "3        3  24/12/2024 2:07  24/12/2024 2:12     IP Address    88.98.240.100   \n",
      "4        4  24/12/2024 2:10  24/12/2024 2:14     IP Address   81.158.156.157   \n",
      "..     ...              ...              ...            ...              ...   \n",
      "736    740  24/12/2024 3:30  24/12/2024 3:34     IP Address    185.58.164.46   \n",
      "737    741  24/12/2024 3:30  24/12/2024 3:35     IP Address     31.51.53.188   \n",
      "738    742  24/12/2024 3:30  24/12/2024 3:35     IP Address    92.26.192.201   \n",
      "739    743  24/12/2024 3:30  24/12/2024 3:35     IP Address      2.24.84.207   \n",
      "740    744  24/12/2024 3:31  24/12/2024 3:38     IP Address     77.100.2.174   \n",
      "\n",
      "     Progress  Duration (in seconds)  Finished     RecordedDate  \\\n",
      "0    Progress  Duration (in seconds)  Finished    Recorded Date   \n",
      "1         100                    163      TRUE  24/12/2024 2:11   \n",
      "2         100                    217      TRUE  24/12/2024 2:12   \n",
      "3         100                    270      TRUE  24/12/2024 2:12   \n",
      "4         100                    236      TRUE  24/12/2024 2:14   \n",
      "..        ...                    ...       ...              ...   \n",
      "736       100                    222      TRUE  24/12/2024 3:34   \n",
      "737       100                    272      TRUE  24/12/2024 3:35   \n",
      "738       100                    292      TRUE  24/12/2024 3:35   \n",
      "739       100                    289      TRUE  24/12/2024 3:35   \n",
      "740       100                    431      TRUE  24/12/2024 3:38   \n",
      "\n",
      "            ResponseId  ... correct2     time_first click2  \\\n",
      "0          Response ID  ...        0  Timing - First Click   \n",
      "1    R_8nI2jhRWzOwxXfp  ...        1                 1.263   \n",
      "2    R_87Uypazf8vHr6Bb  ...        1                 5.911   \n",
      "3    R_8kGGayHvemTKNm1  ...        1                 1.803   \n",
      "4    R_8ZQDmGo6gANCW2F  ...        1                 2.004   \n",
      "..                 ...  ...      ...                   ...   \n",
      "736  R_2iAwzEcyPoERyil  ...        1                 2.743   \n",
      "737  R_8DN2uMeJ5jXKTGZ  ...        1                 1.706   \n",
      "738  R_2YREjucMRIJo3YT  ...        1                  2.76   \n",
      "739  R_8qawmjZS6yvV7Cc  ...        1                 1.694   \n",
      "740  R_8iLkd2ewlBrbDRD  ...        1                 2.162   \n",
      "\n",
      "        time_last click2     time_click count2 version3 count3 correct3  \\\n",
      "0    Timing - Last Click  Timing - Click Count        0      0        0   \n",
      "1                  1.263                     1        0      1        1   \n",
      "2                  5.911                     1        1      1        1   \n",
      "3                  1.803                     1        0      1        1   \n",
      "4                  2.004                     1        0      1        1   \n",
      "..                   ...                   ...      ...    ...      ...   \n",
      "736                2.743                     1        1      1        1   \n",
      "737                 2.58                     2        1      1        1   \n",
      "738                 2.76                     1        0      1        1   \n",
      "739                1.694                     1        0      1        1   \n",
      "740                2.162                     1        1      1        1   \n",
      "\n",
      "        time_first click3     time_last click3     time_click count3  \n",
      "0    Timing - First Click  Timing - Last Click  Timing - Click Count  \n",
      "1                   1.579                1.579                     1  \n",
      "2                   6.189                6.189                     1  \n",
      "3                    3.55                 3.55                     1  \n",
      "4                   5.643                5.643                     1  \n",
      "..                    ...                  ...                   ...  \n",
      "736                 3.002                3.002                     1  \n",
      "737                 1.459                2.618                     2  \n",
      "738                 2.213                2.213                     1  \n",
      "739                 2.196                2.196                     1  \n",
      "740                 4.099                4.099                     1  \n",
      "\n",
      "[741 rows x 3541 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "packNum = 3\n",
    "shelfNum = 20\n",
    "verNum = 2\n",
    "bottleNum = 27\n",
    "df4 = transfer(df3, packNum, shelfNum, verNum, bottleNum).reset_index()\n",
    "print(df4)\n",
    "# df4['Q948_First Click'].to_csv('df4_original4.csv')\n",
    "# df4['Q1048_First Click'].to_csv('df4_change1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step5: transfer data into task level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('process_raw.csv')\n",
    "# df4 = pd.read_csv('process_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/5bx135bd1sn42gnywk_3s_pc0000gn/T/ipykernel_59791/2193761197.py:1: DtypeWarning: Columns (6,7,8,11,12,13,14,15,16,19,20,21,22,24,25,26,27,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,66,67,68,69,70,71,72,73,74,75,76,77,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,727,728,729,730,731,732,733,734,735,736,737,738,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3499,3500,3501,3502,3503,3504,3505,3506,3509,3510,3511,3512,3527,3528,3529,3533,3534,3535,3539,3540,3541) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv('process_raw.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  index        StartDate          EndDate         Status  \\\n",
      "0             0      0       Start Date         End Date  Response Type   \n",
      "1             1      1  24/12/2024 2:08  24/12/2024 2:11     IP Address   \n",
      "2             2      2  24/12/2024 2:08  24/12/2024 2:12     IP Address   \n",
      "3             3      3  24/12/2024 2:07  24/12/2024 2:12     IP Address   \n",
      "4             4      4  24/12/2024 2:10  24/12/2024 2:14     IP Address   \n",
      "..          ...    ...              ...              ...            ...   \n",
      "736         736    740  24/12/2024 3:30  24/12/2024 3:34     IP Address   \n",
      "737         737    741  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "738         738    742  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "739         739    743  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "740         740    744  24/12/2024 3:31  24/12/2024 3:38     IP Address   \n",
      "\n",
      "           IPAddress  Progress  Duration (in seconds)  Finished  \\\n",
      "0         IP Address  Progress  Duration (in seconds)  Finished   \n",
      "1    185.241.224.233       100                    163      TRUE   \n",
      "2       83.98.59.146       100                    217      TRUE   \n",
      "3      88.98.240.100       100                    270      TRUE   \n",
      "4     81.158.156.157       100                    236      TRUE   \n",
      "..               ...       ...                    ...       ...   \n",
      "736    185.58.164.46       100                    222      True   \n",
      "737     31.51.53.188       100                    272      True   \n",
      "738    92.26.192.201       100                    292      True   \n",
      "739      2.24.84.207       100                    289      True   \n",
      "740     77.100.2.174       100                    431      True   \n",
      "\n",
      "        RecordedDate  ... correct3     time_first click3     time_last click3  \\\n",
      "0      Recorded Date  ...        0  Timing - First Click  Timing - Last Click   \n",
      "1    24/12/2024 2:11  ...        1                 1.579                1.579   \n",
      "2    24/12/2024 2:12  ...        1                 6.189                6.189   \n",
      "3    24/12/2024 2:12  ...        1                  3.55                 3.55   \n",
      "4    24/12/2024 2:14  ...        1                 5.643                5.643   \n",
      "..               ...  ...      ...                   ...                  ...   \n",
      "736  24/12/2024 3:34  ...        1                 3.002                3.002   \n",
      "737  24/12/2024 3:35  ...        1                 1.459                2.618   \n",
      "738  24/12/2024 3:35  ...        1                 2.213                2.213   \n",
      "739  24/12/2024 3:35  ...        1                 2.196                2.196   \n",
      "740  24/12/2024 3:38  ...        1                 4.099                4.099   \n",
      "\n",
      "        time_click count3 flow1 flow2 flow3    task1    task2    task3  \n",
      "0    Timing - Click Count   NaN   NaN   NaN      NaN      NaN      NaN  \n",
      "1                       1   2.0   1.0   3.0  FL_1252  FL_1237  FL_1540  \n",
      "2                       1   2.0   3.0   1.0  FL_1252  FL_1540  FL_1237  \n",
      "3                       1   1.0   3.0   2.0  FL_1237  FL_1540  FL_1252  \n",
      "4                       1   3.0   1.0   2.0  FL_1540  FL_1237  FL_1252  \n",
      "..                    ...   ...   ...   ...      ...      ...      ...  \n",
      "736                     1   3.0   1.0   2.0  FL_1540  FL_1237  FL_1252  \n",
      "737                     2   3.0   1.0   2.0  FL_1540  FL_1237  FL_1252  \n",
      "738                     1   1.0   2.0   3.0  FL_1237  FL_1252  FL_1540  \n",
      "739                     1   2.0   3.0   1.0  FL_1252  FL_1540  FL_1237  \n",
      "740                     1   2.0   3.0   1.0  FL_1252  FL_1540  FL_1237  \n",
      "\n",
      "[741 rows x 3548 columns]\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('process_raw.csv')\n",
    "flow_dict = {\n",
    "    'FL_1237': 1 , 'FL_1252': 2, 'FL_1540': 3}\n",
    "\n",
    "df4_copy_copy = copy.deepcopy(df4)\n",
    "\n",
    "# Extract the flow codes into separate columns\n",
    "df4_copy_copy[['flow1', 'flow2', 'flow3']] = df4['FL_1236_DO'].str.extract(\n",
    "    r'(FL_\\d+)\\|(FL_\\d+)\\|(FL_\\d+)'\n",
    ")\n",
    "\n",
    "df4_copy_copy[['task1', 'task2', 'task3']] = df4['FL_1236_DO'].str.extract(\n",
    "    r'(FL_\\d+)\\|(FL_\\d+)\\|(FL_\\d+)'\n",
    ")\n",
    "\n",
    "# Replace the flow strings with their corresponding numeric values using flow_dict\n",
    "df4_copy_copy[['flow1', 'flow2', 'flow3']] = df4_copy_copy[[\n",
    "    'flow1', 'flow2', 'flow3']].replace(flow_dict)\n",
    "print(df4_copy_copy)\n",
    "df4_copy_copy.to_csv('process_raw_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  index        StartDate          EndDate         Status  \\\n",
      "0             0      0       Start Date         End Date  Response Type   \n",
      "1             1      1  24/12/2024 2:08  24/12/2024 2:11     IP Address   \n",
      "2             2      2  24/12/2024 2:08  24/12/2024 2:12     IP Address   \n",
      "3             3      3  24/12/2024 2:07  24/12/2024 2:12     IP Address   \n",
      "4             4      4  24/12/2024 2:10  24/12/2024 2:14     IP Address   \n",
      "..          ...    ...              ...              ...            ...   \n",
      "736         736    740  24/12/2024 3:30  24/12/2024 3:34     IP Address   \n",
      "737         737    741  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "738         738    742  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "739         739    743  24/12/2024 3:30  24/12/2024 3:35     IP Address   \n",
      "740         740    744  24/12/2024 3:31  24/12/2024 3:38     IP Address   \n",
      "\n",
      "           IPAddress  Progress  Duration (in seconds)  Finished  \\\n",
      "0         IP Address  Progress  Duration (in seconds)  Finished   \n",
      "1    185.241.224.233       100                    163      TRUE   \n",
      "2       83.98.59.146       100                    217      TRUE   \n",
      "3      88.98.240.100       100                    270      TRUE   \n",
      "4     81.158.156.157       100                    236      TRUE   \n",
      "..               ...       ...                    ...       ...   \n",
      "736    185.58.164.46       100                    222      True   \n",
      "737     31.51.53.188       100                    272      True   \n",
      "738    92.26.192.201       100                    292      True   \n",
      "739      2.24.84.207       100                    289      True   \n",
      "740     77.100.2.174       100                    431      True   \n",
      "\n",
      "        RecordedDate  ... flow3    task1    task2    task3  \\\n",
      "0      Recorded Date  ...   NaN      NaN      NaN      NaN   \n",
      "1    24/12/2024 2:11  ...   3.0  FL_1252  FL_1237  FL_1540   \n",
      "2    24/12/2024 2:12  ...   1.0  FL_1252  FL_1540  FL_1237   \n",
      "3    24/12/2024 2:12  ...   2.0  FL_1237  FL_1540  FL_1252   \n",
      "4    24/12/2024 2:14  ...   2.0  FL_1540  FL_1237  FL_1252   \n",
      "..               ...  ...   ...      ...      ...      ...   \n",
      "736  24/12/2024 3:34  ...   2.0  FL_1540  FL_1237  FL_1252   \n",
      "737  24/12/2024 3:35  ...   2.0  FL_1540  FL_1237  FL_1252   \n",
      "738  24/12/2024 3:35  ...   3.0  FL_1237  FL_1252  FL_1540   \n",
      "739  24/12/2024 3:35  ...   1.0  FL_1252  FL_1540  FL_1237   \n",
      "740  24/12/2024 3:38  ...   1.0  FL_1252  FL_1540  FL_1237   \n",
      "\n",
      "    task1_original_shelf task1_change_shelf task2_original_shelf  \\\n",
      "0                   None               None                 None   \n",
      "1                      7               None                    9   \n",
      "2                     20               None                   15   \n",
      "3                   None                  7                 None   \n",
      "4                      2               None                 None   \n",
      "..                   ...                ...                  ...   \n",
      "736                 None                 14                 None   \n",
      "737                    2               None                   20   \n",
      "738                 None                 10                 None   \n",
      "739                   10               None                 None   \n",
      "740                 None                 11                   11   \n",
      "\n",
      "    task2_change_shelf task3_original_shelf task3_change_shelf  \n",
      "0                 None                 None               None  \n",
      "1                 None                   20               None  \n",
      "2                 None                 None                 10  \n",
      "3                   10                   11               None  \n",
      "4                    1                    9               None  \n",
      "..                 ...                  ...                ...  \n",
      "736                  8                 None                 16  \n",
      "737               None                 None                  9  \n",
      "738                 12                    1               None  \n",
      "739                 14                   18               None  \n",
      "740               None                 None                 13  \n",
      "\n",
      "[741 rows x 3554 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_shelf(row):\n",
    "    if row:\n",
    "        parts = row.split('_shelf')\n",
    "        if len(parts) > 1:\n",
    "#             print(parts[1].split('|')[0])\n",
    "            return parts[1].split('|')[0]\n",
    "    return None\n",
    "\n",
    "for i in range(1, 4):\n",
    "    original_col = f'SearchTask{i}:originalbottle{i}Question_DO'\n",
    "    change_col = f'SearchTask{i}:changebottle{i}Question_DO'\n",
    "    original_shelf_col = f'task{i}_original_shelf'\n",
    "    change_shelf_col = f'task{i}_change_shelf'\n",
    "#     df4_copy_copy[original_shelf_col] = df4_copy_copy[original_col].apply(lambda x: extract_shelf(x[0]))\n",
    "#     df4_copy_copy[change_shelf_col] = df4_copy_copy[change_col].apply(lambda x: extract_shelf(x[1]))\n",
    "    df4_copy_copy[original_shelf_col] = df4_copy_copy[original_col].apply(lambda x: extract_shelf(str(x)))\n",
    "    df4_copy_copy[change_shelf_col] = df4_copy_copy[change_col].apply(lambda x: extract_shelf(str(x)))\n",
    "# Display the modified DataFrame with new columns\n",
    "print(df4_copy_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 740/740 [00:13<00:00, 53.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID                ProlificID DemoBuy DemoFamilarity DemoClear  \\\n",
      "0       1  5c094b4b1907db00016017d7       1              4         5   \n",
      "1       1  5c094b4b1907db00016017d7       1              4         5   \n",
      "2       1  5c094b4b1907db00016017d7       1              4         5   \n",
      "3       2  60148ce8ea15974d855c06d5       1              5         4   \n",
      "4       2  60148ce8ea15974d855c06d5       1              5         4   \n",
      "...   ...                       ...     ...            ...       ...   \n",
      "2215  739  6730f2e20f5915ff4ad2c07d       1              4       5.0   \n",
      "2216  739  6730f2e20f5915ff4ad2c07d       1              4       5.0   \n",
      "2217  740  5caf6864971a7b0012dc7562       1              5       4.0   \n",
      "2218  740  5caf6864971a7b0012dc7562       1              5       4.0   \n",
      "2219  740  5caf6864971a7b0012dc7562       1              5       4.0   \n",
      "\n",
      "     DemoComplete DemoInternet DemoAge DemoGender TaskID Version  \\\n",
      "0               1            1       2          1      1       0   \n",
      "1               1            1       2          1      2       0   \n",
      "2               1            1       2          1      3       0   \n",
      "3               1            2       6          1      1       0   \n",
      "4               1            2       6          1      2       0   \n",
      "...           ...          ...     ...        ...    ...     ...   \n",
      "2215            1            1       5          1      2       1   \n",
      "2216            1            1       5          1      3       0   \n",
      "2217            1            1       3          1      1       1   \n",
      "2218            1            1       3          1      2       0   \n",
      "2219            1            1       3          1      3       1   \n",
      "\n",
      "     ClickRegionCount CorrectTarget TimeFirstClick TimeLastClick  \\\n",
      "0                   1             1          0.794         1.535   \n",
      "1                   1             1          1.263         1.263   \n",
      "2                   1             1          1.579         1.579   \n",
      "3                   1             1          3.958         3.958   \n",
      "4                   1             1          5.911         5.911   \n",
      "...               ...           ...            ...           ...   \n",
      "2215                1             1          1.694         1.694   \n",
      "2216                1             1          2.196         2.196   \n",
      "2217                1             1          2.003         2.003   \n",
      "2218                1             1          2.162         2.162   \n",
      "2219                1             1          4.099         4.099   \n",
      "\n",
      "     TimeClickCount Flow OriginalShelf ChangeShelf Shelf  \n",
      "0                 2    2             7        None     7  \n",
      "1                 1    1             9        None     9  \n",
      "2                 1    3            20        None    20  \n",
      "3                 1    3            20        None    20  \n",
      "4                 1    1            15        None    15  \n",
      "...             ...  ...           ...         ...   ...  \n",
      "2215              1    1          None          14    14  \n",
      "2216              1    2            18        None    18  \n",
      "2217              1    3          None          11    11  \n",
      "2218              1    1            11        None    11  \n",
      "2219              1    2          None          13    13  \n",
      "\n",
      "[2220 rows x 20 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the final dataframe\n",
    "df5 = pd.DataFrame(columns = [\n",
    "    'ID', 'ProlificID', 'DemoBuy', 'DemoFamilarity', 'DemoClear', \n",
    "    'DemoComplete', 'DemoInternet', 'DemoAge', 'DemoGender', \n",
    "    'TaskID', 'Version', 'ClickRegionCount', 'CorrectTarget', \n",
    "    'TimeFirstClick', 'TimeLastClick', 'TimeClickCount', 'Flow'\n",
    "])\n",
    "\n",
    "# Iterate over the rows of df4_copy_copy\n",
    "for i in tqdm(range(1,df4_copy_copy.shape[0])):\n",
    "    # Extract demographic and other static information\n",
    "    df_sub_level = df4_copy_copy.loc[i, ['Q1324', 'demo_buy_online', 'demo_familarity_1', 'demo_img_clear_1', 'demo_img_complete', 'demo_internet_1', 'Qage', 'Qgender']]\n",
    "    df_sub_level = df_sub_level.to_frame().T\n",
    "    df_sub_task_level = pd.DataFrame(np.repeat(df_sub_level.values, packNum, axis=0))\n",
    "    df_id = pd.DataFrame(np.repeat(i, packNum))\n",
    "    df_sub_task_level = pd.concat([df_id, df_sub_task_level], axis=1, ignore_index=True)\n",
    "    df_sub_task_level.columns = ['ID', 'ProlificID', 'DemoBuy', 'DemoFamilarity', 'DemoClear', 'DemoComplete', 'DemoInternet', 'DemoAge', 'DemoGender']\n",
    "    \n",
    "    # Initialize task level dataframe\n",
    "    df_task_level_new = pd.DataFrame(columns=['Version', 'ClickRegionCount', 'CorrectTarget', 'TimeFirstClick', 'TimeLastClick', 'TimeClickCount', 'Flow'])\n",
    "    \n",
    "    # Extract the flow values for this row (flow1 to flow8)\n",
    "    flow_values = df4_copy_copy.loc[i, ['flow1', 'flow2', 'flow3']].values\n",
    "    shelf_values = df4_copy_copy.loc[i, ['task1_original_shelf', 'task1_change_shelf', 'task2_original_shelf', 'task2_change_shelf','task3_original_shelf', 'task3_change_shelf']].values\n",
    "    # Iterate over each task (package) and extract task-level information\n",
    "    df_task_id = pd.DataFrame(np.arange(1, packNum + 1, dtype=int))\n",
    "    for j in range(1, packNum + 1):\n",
    "        # Extract task-level data\n",
    "        df_task_level = df4_copy_copy.loc[i, [\n",
    "            'version' + str(j),\n",
    "            'count' + str(j),\n",
    "            'correct' + str(j),\n",
    "            'time_first click' + str(j),\n",
    "            'time_last click' + str(j),\n",
    "            'time_click count' + str(j),\n",
    "            'task' + str(j) + '_original_shelf',\n",
    "            'task' + str(j) + '_change_shelf'\n",
    "        ]].to_frame().T\n",
    "\n",
    "        df_task_level.columns = ['Version', 'ClickRegionCount', 'CorrectTarget', 'TimeFirstClick', 'TimeLastClick', 'TimeClickCount', 'OriginalShelf', 'ChangeShelf']\n",
    "        \n",
    "        # Find the flow column corresponding to the current task number j\n",
    "        flow_position = np.where(flow_values == j)[0][0] + 1  # +1 to get flow column index (flow1 = 1, flow2 = 2, ..., flow8 = 8)\n",
    "        # Assign the flow column index (flow_position) as the flow value\n",
    "        df_task_level['Flow'] = flow_position\n",
    "        # Determine which shelf value to keep\n",
    "        df_task_level['Shelf'] = df_task_level.apply(lambda row: row['OriginalShelf'] if pd.notnull(row['OriginalShelf']) else row['ChangeShelf'], axis=1)\n",
    "            # Append the task-level data to the new dataframe\n",
    "        df_task_level_new = pd.concat([df_task_level_new, df_task_level], axis=0, ignore_index=True)\n",
    "\n",
    "    # Combine task IDs and task-level details\n",
    "    df_task_level_concat = pd.concat([df_task_id, df_task_level_new], axis=1, ignore_index=True)\n",
    "    df_task_level_concat.columns = ['TaskID', 'Version', 'ClickRegionCount', 'CorrectTarget', 'TimeFirstClick', 'TimeLastClick', 'TimeClickCount', 'Flow', 'OriginalShelf', 'ChangeShelf', 'Shelf']\n",
    "\n",
    "    # Combine subject-level and task-level data\n",
    "    df5_part = pd.concat([df_sub_task_level, df_task_level_concat], axis=1, ignore_index=True)\n",
    "\n",
    "    df5_part.columns = ['ID', 'ProlificID', 'DemoBuy', 'DemoFamilarity', 'DemoClear', 'DemoComplete', 'DemoInternet', 'DemoAge', 'DemoGender', 'TaskID', 'Version', 'ClickRegionCount', 'CorrectTarget', 'TimeFirstClick', 'TimeLastClick', 'TimeClickCount', 'Flow','OriginalShelf', 'ChangeShelf', 'Shelf']\n",
    "    # Append to the final dataframe\n",
    "    df5 = pd.concat([df5, df5_part], axis=0, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to CSV\n",
    "print(df5)\n",
    "df5.to_csv('dataclean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
